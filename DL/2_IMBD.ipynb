{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Conv2D, MaxPooling2D,Input\n",
    "from keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d08665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will preprocess the data by scaling the pixel values to be between 0 and 1, and then reshaping\n",
    "# the images to be 28x28 pixels.\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "# 28, 28 comes from width, height, 1 comes from the number of channels\n",
    "# -1 means that the length in that dimension is inferred.\n",
    "# This is done based on the constraint that the number of elements in an ndarray or Tensor when\n",
    "# reshaped must remain the same.\n",
    "# each image is a row vector (784 elements) and there are lots of such rows (let it be n, so there are 784n\n",
    "# elements). So TensorFlow can infer that -1 is n.\n",
    "# converting the training_images array to 4 dimensional array with sizes 60000, 28, 28, 1 for 0th to 3rd\n",
    "# dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "\n",
    "# Adding maxpooling layer to get max value within a matrix\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) \n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train the Model\n",
    "# After defining the model, we will compile it and train it on the training data.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1875 is a number of batches. By default batches contain 32 samles.60000 / 32 = 1875\n",
    "# Finally, we will evaluate the performance of the model on the test data.\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7474997",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.argmax(predictions)\n",
    "y_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b5f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654549b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(l)\n",
    "plt.imshow(x_test[:1][0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53382a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
